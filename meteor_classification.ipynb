{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31d0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from os import listdir\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "# authors: \n",
    "#Clarissa Pavao\n",
    "#Yazdan Basir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b71d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists for training images and labels\n",
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "#note for future Clarissa: remove forward slash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882a39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset_img/train\"\n",
    "\n",
    "#converting meteor images to np arrays and adding to training set\n",
    "images = Path(path + \"/meteors\").glob('*.jpg') #finds images\n",
    "for image in images:\n",
    "    img = Image.open(image)                    #opens as image object (str)\n",
    "    pic = np.asarray(img)                      #converts to np.array\n",
    "    train_images.append(pic)\n",
    "    #train_labels.append('meteor')\n",
    "    train_labels.append(1)\n",
    "\n",
    "\n",
    "#converting nonmeteor images to np arrays and adding to training set\n",
    "images = Path(path + \"/nonmeteors\").glob('*.jpg') #finds images\n",
    "for image in images:\n",
    "    img = Image.open(image)                   #opens as image object (str)\n",
    "    pic = np.asarray(img)                     #converts to np.array\n",
    "    train_images.append(pic)\n",
    "    #train_labels.append('nonmeteor')\n",
    "    train_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47cc7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"dataset_img/test\"\n",
    "\n",
    "#converting meteor images to np arrays and adding to testing set\n",
    "images = Path(path + \"/meteors\").glob('*.jpg') #finds images\n",
    "for image in images:\n",
    "    img = Image.open(image)                    #opens as image object (str)\n",
    "    pic = np.asarray(img)                      #converts to np.array\n",
    "    test_images.append(pic)\n",
    "    #test_labels.append('meteor')\n",
    "    test_labels.append(1)\n",
    "\n",
    "\n",
    "#converting nonmeteor images to np arrays and adding to testing set\n",
    "images = Path(path + \"/nonmeteors\").glob('*.jpg') #finds images\n",
    "for image in images:\n",
    "    img = Image.open(image)                    #opens as image object (str)\n",
    "    pic = np.asarray(img)                      #converts to np.array\n",
    "    test_images.append(pic)    \n",
    "    #test_labels.append('nonmeteor')\n",
    "    test_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb6c9866",
   "metadata": {},
   "outputs": [],
   "source": [
 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f452d441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137, 480, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# normalize the data\n",
    "train_images = (np.asarray(train_images)) / 255\n",
    "test_images = (np.asarray(test_images)) / 255\n",
    "#print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae54abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1137,)\n"
     ]
    }
   ],
   "source": [
    "# convert labels to arrays\n",
    "train_labels = (np.asarray(train_labels))\n",
    "test_labels = (np.asarray(test_labels))\n",
    "#print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe4d3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape = (480,640,3)))\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu')) #layer 1. process 64 filters of size 3x3 over our input data. Activation func relu to the output of each convolution operation \n",
    "\n",
    "model.add(layers.MaxPooling2D((2,2)))                    #max pooling using 2x2 samples and a stride 2\n",
    "model.add(layers.Conv2D(64,(3,3), activation = 'relu')) #layer 2\n",
    "\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu')) #layer 3\n",
    "\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "\n",
    "#adding dense layers/feature extractions\n",
    "\n",
    "model.add(layers.Flatten())                              #reshape to 480x640 array into a vector of 307,200 neurons so each pixel will associated with one neuron\n",
    "model.add(layers.Dense(64, activation='softmax'))       #this layer will be fully connected and each neuron from the previous layer connects to each neuron of this layer\n",
    "model.add(layers.Dense(2))                               # output layer. dense layer. the 2 is for the two labels (meteors and nonmeteors). The acitvation softmax is used on this layer to calculate a prob distribution for each class. \n",
    "\n",
    "\n",
    "#model.add(layers.Dense(64, activation = 'relu')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6181bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 478, 638, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 239, 319, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 237, 317, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 118, 158, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 116, 156, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 58, 78, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 56, 76, 128)       147584    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 544768)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               69730432  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,101,506\n",
      "Trainable params: 70,101,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# see what the model is doing \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "217e9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(train_images.shape)\n",
    "# print(train_labels.shape)\n",
    "# print(test_images.shape)\n",
    "# print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3129c294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08ac7893",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#create model\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f15d79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "36/36 [==============================] - 81s 2s/step - loss: 0.6916 - accuracy: 0.5620\n",
      "Epoch 2/2\n",
      "36/36 [==============================] - 77s 2s/step - loss: 0.6886 - accuracy: 0.5743\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(train_images, train_labels, epochs = 2, verbose = \"auto\", \n",
    "                   shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a3c16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "#model.fit(train_images, train_labels, epochs = 2)  # we pass the data, labels and epochs and watch the magic!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86acc831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 528ms/step - loss: 0.6528 - accuracy: 0.9495\n",
      "Test accuracy: 0.9494950175285339\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose = 1)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28fe1588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check to see our accurate our predictions are\n",
    "# predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ee364e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea038183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax(predictions[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32e9d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad90ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
